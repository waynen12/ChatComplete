# Docker Compose for AI Knowledge Manager
version: '3.8'

services:
  # Main application container
  ai-knowledge-manager:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: ai-knowledge-manager
    ports:
      - "8080:7040"  # Map to port 8080 externally for easy access
    volumes:
      - ai-knowledge-data:/app/data          # Persistent data storage
      - ./logs:/app/data/logs               # Mount logs for development
    environment:
      - ASPNETCORE_ENVIRONMENT=Production
      - DOTNET_RUNNING_IN_CONTAINER=true
      - VectorStore__Provider=Qdrant        # Use Qdrant when available
      - VectorStore__Qdrant__Host=qdrant    # Reference Qdrant service
      - VectorStore__Qdrant__Port=6334      # gRPC port
      # API keys - set these via .env file or environment
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    depends_on:
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7040/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - ai-services

  # Qdrant vector database (optional but recommended)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
    networks:
      - ai-services
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

volumes:
  ai-knowledge-data:
    driver: local
    name: ai-knowledge-data
  qdrant-data:
    driver: local
    name: qdrant-data

networks:
  ai-services:
    driver: bridge
    name: ai-services-network