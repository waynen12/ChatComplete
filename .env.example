# AI Knowledge Manager - Environment Variables
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# OpenAI (GPT-4, GPT-4o, GPT-5)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic (Claude Sonnet 4)
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Google Gemini (Gemini 2.5 Flash)
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# Ollama (Local LLMs)
# No API key needed - runs locally in Docker container

# =============================================================================
# Advanced Configuration (Optional)
# =============================================================================

# Vector Store Configuration
# Default: Qdrant (included in docker-compose)
# ChatCompleteSettings__VectorStore__Provider=Qdrant
# ChatCompleteSettings__VectorStore__Qdrant__Host=qdrant
# ChatCompleteSettings__VectorStore__Qdrant__Port=6334

# Ollama Configuration
# Default: http://ollama:11434 (Docker), http://localhost:11434 (local dev)
# ChatCompleteSettings__OllamaBaseUrl=http://ollama:11434

# Database Path (Container)
# Default: /app/data/knowledge.db
# ChatCompleteSettings__DatabasePath=/app/data/knowledge.db

# Logging Level
# Options: Debug, Information, Warning, Error
# Logging__LogLevel__Default=Information

# =============================================================================
# Notes
# =============================================================================

# - At least ONE API key is required (OpenAI, Anthropic, or Gemini)
# - Ollama works without API keys (fully local)
# - Commented lines show default values - only uncomment to override
# - Never commit this file with real API keys (it's in .gitignore)
